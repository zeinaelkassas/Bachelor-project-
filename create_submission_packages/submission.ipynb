{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy.stats import hmean\n",
    "import numpy as np\n",
    "import os\n",
    "from common.data.datasets.dcase2021_task2 import MACHINE_TYPES\n",
    "\n",
    "from experiments.evaluate import evaluate\n",
    "from create_submission_packages.submission_help import load_data_frame, aggregate_metrics\n",
    "import yaml\n",
    "import io\n",
    "\n",
    "LOG_DIR = os.path.join('..', 'logs')\n",
    "OUT_DIR = os.path.join('zip_package_root', 'task2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def aggregate_fun_max(df, machine_type):\n",
    "    return df.groupby('path').max()\n",
    "\n",
    "def aggregate_fun_best(df, machine_type):\n",
    "    if machine_type in ['ToyTrain']:\n",
    "        return df.groupby('path').max()\n",
    "    else:\n",
    "        return df.groupby('path').mean()\n",
    "\n",
    "def aggregate_fun(df, machine_type):\n",
    "    return df.groupby('path').mean()\n",
    "\n",
    "def aggregate_metrics_yaml(df):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for i in range(7):\n",
    "        metrics = evaluate(df.loc[(df['train'] == False) & (df['machine_type_idx'] == i)], machine_type_idx=i,section=-1)\n",
    "\n",
    "        aucs = []\n",
    "        paucs = []\n",
    "        m = MACHINE_TYPES[i]\n",
    "        \n",
    "        for s in [0, 1, 2]:  # metrics[m]:\n",
    "            for d in metrics[m][s]:\n",
    "                aucs.append(metrics[m][s][d]['auc'])\n",
    "                paucs.append(metrics[m][s][d]['pauc'])\n",
    "\n",
    "        results[m] = hmean(aucs), hmean(paucs)\n",
    "    return results\n",
    "\n",
    "def create_submission_package(submission_id, df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    id_ = {'ae': 1, 'made': 1, 'maf': 2, 'clf': 3, 'comb': 4}[submission_id]\n",
    "    submission_id_ = f'Primus_CPJKU_task2_{id_}'\n",
    "\n",
    "    submission_dir = os.path.join(OUT_DIR, submission_id_)\n",
    "    os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "    for d in ['source', 'target']:\n",
    "        for m in MACHINE_TYPES:\n",
    "            for s in [0, 1, 2, 3, 4, 5]:\n",
    "\n",
    "                to_save_mask = (df['train'] == False) & (df['machine_type_idx'] == MACHINE_TYPES.index(m)) & (df['section'] == s) & (df['source'] == (d == 'source'))\n",
    "                to_normalize_mask = (df['train'] == True) & (df['machine_type_idx'] == MACHINE_TYPES.index(m)) & (df['section'] == s)\n",
    "\n",
    "                filename = f\"anomaly_score_{m}_section_{s}_{d}.csv\"\n",
    "                if s > 2:\n",
    "                    df.loc[to_save_mask, 'anomaly_score'].to_csv(os.path.join(submission_dir, filename), header=False)\n",
    "\n",
    "                shape_hat, loc_hat, scale_hat = scipy.stats.gamma.fit(df.loc[to_normalize_mask, 'anomaly_score'].to_numpy())\n",
    "                decision_threshold = scipy.stats.gamma.ppf(q=0.9, a=shape_hat, loc=loc_hat, scale=scale_hat)\n",
    "\n",
    "                filename = f\"decision_result_{m}_section_{s}_{d}.csv\"\n",
    "                df['decision_result'] = df['anomaly_score'] > decision_threshold\n",
    "                if s > 2:\n",
    "                    df[\"decision_result\"] = df[\"decision_result\"].astype(int)\n",
    "                    df.loc[to_save_mask, 'decision_result'].to_csv(os.path.join(submission_dir, filename), header=False)\n",
    "\n",
    "   \n",
    "    # Read YAML file\n",
    "    with open(\"template.meta.yaml\", 'r') as stream:\n",
    "        template = yaml.safe_load(stream)\n",
    "    \n",
    "    name = {\n",
    "        'ae': 'Autoencoder with PO Loss',\n",
    "        'made': 'MADE with PO Loss',\n",
    "        'maf': 'MAF with PO Loss', \n",
    "        'clf': 'Domain Adapted ResNet with PO Loss', \n",
    "        'comb': 'Ensemble with PO Loss'\n",
    "    }[submission_id]\n",
    "    \n",
    "    abbreviation = {\n",
    "        'ae': 'AE', \n",
    "        'made': 'MADE', \n",
    "        'maf': 'MAF', \n",
    "        'clf': 'ResNet', \n",
    "        'comb': 'Ensemble'\n",
    "    }[submission_id]\n",
    "    \n",
    "    machine_learning_method = {\n",
    "        'ae': 'AE',\n",
    "        'made': 'MADE',\n",
    "        'maf': 'MAF',\n",
    "        'clf': 'ResNet',\n",
    "        'comb': 'Ensemble'\n",
    "    }[submission_id]\n",
    "    \n",
    "    complexity = {\n",
    "        'ae': 2072000,\n",
    "        'made': 144900000,\n",
    "        'maf': 228200000,\n",
    "        'clf': 46200000,\n",
    "        'comb': 421372000\n",
    "    }[submission_id]\n",
    "    \n",
    "    template['submission']['label'] = submission_id_\n",
    "    template['submission']['name'] = name\n",
    "    template['submission']['abbreviation'] = abbreviation\n",
    "\n",
    "    template['system']['description']['machine_learning_method'] = machine_learning_method\n",
    "    if submission_id == 'comb':\n",
    "        template['system']['description']['ensemble_method_subsystem_count'] = 3\n",
    "        template['system']['description']['decision_making'] = 'mean'\n",
    "        template['system']['description']['domain_adaptation_method'] = 'Contrastive Semantic Alignment'\n",
    "    elif submission_id == 'clf':\n",
    "        template['system']['description']['domain_adaptation_method'] = 'Contrastive Semantic Alignment'\n",
    "        \n",
    "    template['system']['complexity']['total_parameters'] = complexity\n",
    "    \n",
    "    metrics = aggregate_metrics_yaml(df)\n",
    "    for m in metrics:\n",
    "        template['results']['development_dataset'][m]['harmonic_mean_auc'] = float(metrics[m][0]) *100\n",
    "        template['results']['development_dataset'][m]['harmonic_mean_pauc'] = float(metrics[m][1]) *100\n",
    "    \n",
    "    # Write YAML file\n",
    "    with io.open(os.path.join(submission_dir, f'Primus_CPJKU_task2_{id_}.meta.yaml'), 'w', encoding='utf8') as outfile:\n",
    "        yaml.dump(template, outfile, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# pump, slider -> no po\n",
    "\n",
    "classification = {\n",
    "    'source': {\n",
    "        'ToyTrain': ['dba703948e3c4c04a4c7697510c430c8'],\n",
    "        'ToyCar': ['5fbdff2bcd444e738b650affa424d221'],\n",
    "        'valve': ['0230bd7f9f574a4fab2758ccd263fef7'],\n",
    "        'slider': ['70596e0c1c394b17858648f71984c940'],\n",
    "        'pump': ['d516cf02fd3e46f199fd0bcdbe09aaef'],\n",
    "        'gearbox': ['6670d468bf544c55bd998b6c2fcc0b71'],\n",
    "        'fan': ['97fcd5a6e7d24a8c83f77e286384f5aa']\n",
    "    },\n",
    "    'target': {\n",
    "        'ToyTrain': ['0692450061ff4c54bf510077b1fc23fb'],\n",
    "        'ToyCar': ['08bc33d7e35c4bf5b86b0620689bf8e7'],\n",
    "        'valve': ['247aab1d7651415f9526506a8689047e'],\n",
    "        'slider': ['39666e607e9e4eddba7b74ad916ee765'],\n",
    "        'pump': ['551e9530ebbb4574a522adbea69d2d48'],\n",
    "        'gearbox': ['2c33a109178f4e78927dae7760e63d76'],\n",
    "        'fan': ['d506b9f1e3ba419aabb241d331ca0ee8']\n",
    "    }\n",
    "}\n",
    "\n",
    "classification_df = load_data_frame(classification)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# ToyCar, fan, pump, slider , valve -> other machines\n",
    "# ToyTrain, gearbox -> only same\n",
    "\n",
    "maf = {\n",
    "    'source': {\n",
    "        'ToyTrain': ['e18f736ad2f24b54ae5e75810ef60e09'],\n",
    "        'ToyCar': ['15d68a23d4eb46f8a24a33643f031538'],\n",
    "        'valve': ['03e153ad747d4b3a92427c5cf691365e'],\n",
    "        'slider': ['c5fb329e20a2491aa310ff18ed76a49e'],\n",
    "        'pump': ['70c51092d72640209e2951aa00e19086'],\n",
    "        'gearbox': ['9eefb837119e43ec8fe9ea1ddaf921f8'],\n",
    "        'fan': ['3f56295b34e6499b9484a50a009d4244']\n",
    "    },\n",
    "    'target': {\n",
    "        'ToyTrain': ['e18f736ad2f24b54ae5e75810ef60e09'],\n",
    "        'ToyCar': ['15d68a23d4eb46f8a24a33643f031538'],\n",
    "        'valve': ['03e153ad747d4b3a92427c5cf691365e'],\n",
    "        'slider': ['c5fb329e20a2491aa310ff18ed76a49e'],\n",
    "        'pump': ['70c51092d72640209e2951aa00e19086'],\n",
    "        'gearbox': ['9eefb837119e43ec8fe9ea1ddaf921f8'],\n",
    "        'fan': ['3f56295b34e6499b9484a50a009d4244']\n",
    "    }\n",
    "}\n",
    "\n",
    "maf_df = load_data_frame(maf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same -> gearbox, ToyTrain, ToyCar\n",
    "ae = {\n",
    "    'source': {\n",
    "        'ToyTrain': ['9902e95c2b4341fa9176faf9e07452ba'],\n",
    "        'ToyCar': ['ca7edb887a8640d19b284b033e83ddde'],\n",
    "        'valve': ['f9633473158a4f478f2e8d48075d4960'],\n",
    "        'slider': ['05a15e261fcd4a5d91fdd691ebd44eb4'],\n",
    "        'pump': ['39803953b24c4b8f8be2a567f6e3f853'],\n",
    "        'gearbox': ['58fadba0c17842ca9a529d488ecedd15'],\n",
    "        'fan': ['7715c83b31a24e7ca0a2011b61f8fec6']\n",
    "    },\n",
    "    'target': {\n",
    "        'ToyTrain': ['9902e95c2b4341fa9176faf9e07452ba'],\n",
    "        'ToyCar': ['ca7edb887a8640d19b284b033e83ddde'],\n",
    "        'valve': ['f9633473158a4f478f2e8d48075d4960'],\n",
    "        'slider': ['05a15e261fcd4a5d91fdd691ebd44eb4'],\n",
    "        'pump': ['39803953b24c4b8f8be2a567f6e3f853'],\n",
    "        'gearbox': ['58fadba0c17842ca9a529d488ecedd15'],\n",
    "        'fan': ['7715c83b31a24e7ca0a2011b61f8fec6']\n",
    "    }\n",
    "}\n",
    "\n",
    "ae_df = load_data_frame(ae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all -> fan, pump, slider valve\n",
    "made = {\n",
    "    'source': {\n",
    "        'ToyTrain': ['87eac890ecc2475ab361e7d5e2c145ab'],\n",
    "        'ToyCar': ['1f33112db5144f7da62200b67a6e76d0'],\n",
    "        'valve': ['c6b274a052944f1f877b466b4d5291f4'],\n",
    "        'slider': ['c0cd20d44917422b890275c08e6460d8'],\n",
    "        'pump': ['2c1c0c98aa8f4f4f85aeaefd34fc131e'],\n",
    "        'gearbox': ['d84133c12ab846849a82bff02b76f0c1'],\n",
    "        'fan': ['56abadb62a3643c9bb07fb1fb8b274d6']\n",
    "    },\n",
    "    'target': {\n",
    "        'ToyTrain': ['87eac890ecc2475ab361e7d5e2c145ab'],\n",
    "        'ToyCar': ['1f33112db5144f7da62200b67a6e76d0'],\n",
    "        'valve': ['c6b274a052944f1f877b466b4d5291f4'],\n",
    "        'slider': ['c0cd20d44917422b890275c08e6460d8'],\n",
    "        'pump': ['2c1c0c98aa8f4f4f85aeaefd34fc131e'],\n",
    "        'gearbox': ['d84133c12ab846849a82bff02b76f0c1'],\n",
    "        'fan': ['56abadb62a3643c9bb07fb1fb8b274d6']\n",
    "    }\n",
    "}\n",
    "\n",
    "made_df = load_data_frame(made)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# sanity check\n",
    "\n",
    "overview = pd.DataFrame(\n",
    "    {\n",
    "        'lab':  MACHINE_TYPES,\n",
    "        'classification': aggregate_metrics(classification_df),\n",
    "        'ae': aggregate_metrics(ae_df),\n",
    "        'maf': aggregate_metrics(maf_df),\n",
    "        'made': aggregate_metrics(made_df)\n",
    "    }\n",
    ")\n",
    "\n",
    "overview.plot.bar(x='lab', rot=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "_ = create_submission_package('made', made_df)\n",
    "_ = create_submission_package('maf', maf_df)\n",
    "_ = create_submission_package('clf', classification_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}